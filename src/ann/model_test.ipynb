{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"./data/splited/far/X_test.csv\", header=None).values\n",
    "y_test = pd.read_csv(\"./data/splited/far/y_test.csv\", header=None).values\n",
    "\n",
    "n_towers = 134"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]\n",
    "test_dataset = TrajectoryDataset(X_test, y_test)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(TrajectoryModel, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_dim, 80),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(80, 100),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(100, 105),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(105, output_dim),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando dispositivo: cuda\n"
     ]
    }
   ],
   "source": [
    "# Configuración para GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Usando dispositivo: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.KLDivLoss(reduction='batchmean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar el modelo\n",
    "model = TrajectoryModel(input_dim=X_test.shape[1], output_dim=n_towers).to(device)\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "# model.load_state_dict(torch.load('saved_model/model_trajectory.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Inicializar listas para métricas\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "top10_predictions = [] \n",
    "\n",
    "test_loss = 0\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        # Predicción del modelo\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs.log(), y_batch)\n",
    "        test_loss += loss.item()\n",
    "\n",
    "        # Convertir predicciones a etiquetas (una decodificación one-hot para la etiqueta más probable)\n",
    "        predicted_labels.extend(torch.argmax(outputs, dim=1).cpu().numpy())\n",
    "        true_labels.extend(torch.argmax(y_batch, dim=1).cpu().numpy())\n",
    "\n",
    "        topk_values, topk_indices = torch.topk(outputs, k=10, dim=1)\n",
    "        top10_predictions.extend(topk_indices.cpu().numpy().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calcula la distancia en kilómetros entre dos puntos geográficos usando la fórmula de Haversine.\n",
    "    \"\"\"\n",
    "    R = 6371  # Radio de la Tierra en kilómetros\n",
    "    lat1, lon1, lat2, lon2 = [float(coord) for coord in [lat1, lon1, lat2, lon2]]\n",
    "    lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    distance = R * c\n",
    "\n",
    "    return distance\n",
    "\n",
    "\n",
    "def geospatial_distance(ground_truth, predicted_values):\n",
    "    geospatial_distance = 0\n",
    "\n",
    "    zn_pos = pd.read_csv('./data/zones_centroids.csv')\n",
    "    zone_coords = zn_pos.set_index('zone')[['latitude', 'longitude']].to_dict(orient='index')\n",
    "\n",
    "    for i in range(len(ground_truth)):\n",
    "        lat1, lon1 = zone_coords[ground_truth[i] + 1]['latitude'], zone_coords[ground_truth[i] + 1]['longitude']\n",
    "\n",
    "        lat2, lon2 = zone_coords[predicted_values[i] + 1]['latitude'], zone_coords[predicted_values[i] + 1]['longitude']\n",
    "\n",
    "        # Sumar distancia geoespacial\n",
    "        geospatial_distance += haversine_distance(lat1, lon1, lat2, lon2)\n",
    "\n",
    "    return geospatial_distance / len(ground_truth)  # Promedio de las distancias\n",
    "\n",
    "def topk(true_labels, predicted_labels, k):\n",
    "    topk_token = 0\n",
    "    for i in range(len(true_labels)):\n",
    "        topk_i = predicted_labels[i][:k]\n",
    "        if true_labels[i] in topk_i:\n",
    "            topk_token += 1\n",
    "    topk_score = topk_token / len(true_labels)\n",
    "    return topk_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 3.1795\n",
      "Accuracy: 0.1882\n",
      "Top-3 Accuracy: 0.3911\n",
      "Top-5 Accuracy: 0.5139\n",
      "Top-10 Accuracy: 0.6809\n",
      "Geospatial Distance: 4.8217 km\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.03      0.06        59\n",
      "           1       0.14      0.26      0.18        77\n",
      "           2       0.50      0.01      0.01       141\n",
      "           3       0.00      0.00      0.00       170\n",
      "           4       0.19      0.13      0.16       394\n",
      "           5       0.13      0.09      0.11       276\n",
      "           6       0.00      0.00      0.00       119\n",
      "           7       0.00      0.00      0.00       273\n",
      "           8       0.19      0.55      0.28      3414\n",
      "           9       0.00      0.00      0.00       214\n",
      "          10       0.14      0.09      0.11      1544\n",
      "          11       0.21      0.04      0.07      1654\n",
      "          12       0.19      0.06      0.09      1635\n",
      "          13       0.15      0.00      0.01       818\n",
      "          14       0.00      0.00      0.00        57\n",
      "          15       0.15      0.04      0.06       542\n",
      "          18       0.16      0.22      0.18      2786\n",
      "          19       0.00      0.00      0.00       128\n",
      "          20       0.20      0.10      0.13      1155\n",
      "          22       0.00      0.00      0.00       235\n",
      "          23       0.23      0.08      0.12      1356\n",
      "          24       0.13      0.00      0.01       695\n",
      "          27       0.00      0.00      0.00       183\n",
      "          30       0.11      0.01      0.01       664\n",
      "          31       0.00      0.00      0.00       295\n",
      "          32       0.17      0.05      0.08      1503\n",
      "          33       0.17      0.00      0.00       528\n",
      "          35       0.00      0.00      0.00       413\n",
      "          36       0.26      0.02      0.03       841\n",
      "          37       0.00      0.00      0.00       755\n",
      "          38       0.18      0.35      0.24      3975\n",
      "          39       0.00      0.00      0.00         5\n",
      "          40       0.00      0.00      0.00       578\n",
      "          41       0.15      0.23      0.18      2840\n",
      "          42       0.00      0.00      0.00       368\n",
      "          43       0.00      0.00      0.00       472\n",
      "          45       0.00      0.00      0.00       731\n",
      "          47       0.13      0.26      0.17      2222\n",
      "          48       0.12      0.01      0.01       757\n",
      "          49       0.00      0.00      0.00       191\n",
      "          50       0.00      0.00      0.00       310\n",
      "          51       0.07      0.01      0.02       523\n",
      "          52       0.00      0.00      0.00       137\n",
      "          53       0.18      0.00      0.01       564\n",
      "          54       0.40      0.01      0.02       694\n",
      "          56       0.11      0.05      0.07      1445\n",
      "          57       0.17      0.15      0.16      1135\n",
      "          58       0.05      0.00      0.00       835\n",
      "          59       0.10      0.16      0.12      1130\n",
      "          60       0.17      0.39      0.23      2215\n",
      "          61       0.00      0.00      0.00       102\n",
      "          62       0.00      0.00      0.00       483\n",
      "          63       0.19      0.02      0.04      1080\n",
      "          64       0.00      0.00      0.00       600\n",
      "          65       0.22      0.41      0.28      2384\n",
      "          66       0.13      0.01      0.01      1402\n",
      "          67       0.24      0.55      0.34      1038\n",
      "          68       0.33      0.16      0.22       380\n",
      "          69       0.33      0.26      0.29       284\n",
      "          70       0.00      0.00      0.00        52\n",
      "          71       0.00      0.00      0.00        22\n",
      "          72       0.14      0.26      0.18      1618\n",
      "          73       0.19      0.05      0.08      1094\n",
      "          75       0.00      0.00      0.00       230\n",
      "          76       0.00      0.00      0.00       152\n",
      "          77       0.00      0.00      0.00       438\n",
      "          78       0.30      0.21      0.25       819\n",
      "          79       0.18      0.45      0.26      2592\n",
      "          80       0.50      0.00      0.01       261\n",
      "          82       0.33      0.02      0.03       173\n",
      "          83       0.00      0.00      0.00       237\n",
      "          85       0.25      0.55      0.34      1260\n",
      "          86       0.00      0.00      0.00       296\n",
      "          87       0.24      0.27      0.25      1319\n",
      "          88       0.00      0.00      0.00        18\n",
      "          89       0.50      0.00      0.00       538\n",
      "          90       0.18      0.08      0.11      1554\n",
      "          91       1.00      0.01      0.01       274\n",
      "          92       0.23      0.31      0.26       373\n",
      "          93       0.00      0.00      0.00        62\n",
      "          94       0.00      0.00      0.00       172\n",
      "          95       0.18      0.05      0.08       283\n",
      "          96       0.00      0.00      0.00       215\n",
      "          98       1.00      0.00      0.01       211\n",
      "          99       0.00      0.00      0.00       159\n",
      "         100       0.20      0.16      0.18       626\n",
      "         101       0.31      0.01      0.02      1202\n",
      "         103       0.00      0.00      0.00       534\n",
      "         104       0.00      0.00      0.00        51\n",
      "         105       0.16      0.30      0.20      2371\n",
      "         106       0.00      0.00      0.00       192\n",
      "         107       0.19      0.35      0.24      2304\n",
      "         108       0.00      0.00      0.00       641\n",
      "         109       0.23      0.47      0.31      3024\n",
      "         110       0.11      0.03      0.05      1210\n",
      "         111       0.15      0.24      0.19      2616\n",
      "         112       0.19      0.03      0.05       747\n",
      "         113       0.28      0.33      0.30      1214\n",
      "         114       0.00      0.00      0.00       121\n",
      "         115       0.24      0.11      0.15      1560\n",
      "         116       0.00      0.00      0.00       608\n",
      "         117       0.22      0.34      0.27      1119\n",
      "         118       0.00      0.00      0.00        99\n",
      "         119       0.27      0.06      0.10       865\n",
      "         120       0.16      0.10      0.12      1063\n",
      "         121       0.15      0.02      0.03       324\n",
      "         122       0.00      0.00      0.00       323\n",
      "         123       0.10      0.03      0.05       634\n",
      "         124       0.15      0.05      0.07      1576\n",
      "         125       0.00      0.00      0.00        11\n",
      "         126       0.00      0.00      0.00       255\n",
      "         127       0.26      0.09      0.13      1825\n",
      "         128       0.12      0.01      0.02       232\n",
      "         129       0.17      0.00      0.01       300\n",
      "         130       0.00      0.00      0.00       205\n",
      "         131       0.10      0.00      0.01       442\n",
      "         132       0.27      0.63      0.38      1625\n",
      "         133       0.23      0.16      0.19       756\n",
      "\n",
      "    accuracy                           0.19     96901\n",
      "   macro avg       0.14      0.09      0.08     96901\n",
      "weighted avg       0.17      0.19      0.14     96901\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\alexs\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Calcular métricas adicionales\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "test_loss /= len(test_loader)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "\n",
    "# Precisión\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "for i in [3, 5, 10]:\n",
    "    topk_score = topk(true_labels, top10_predictions, i)\n",
    "    print(f\"Top-{i} Accuracy: {topk_score:.4f}\") \n",
    "\n",
    "geospatial_distance = geospatial_distance(true_labels, predicted_labels)\n",
    "print(f\"Geospatial Distance: {geospatial_distance:.4f} km\")\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(true_labels, predicted_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "import json\n",
    "import folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb2hex(r,g,b):\n",
    "    if type(r)!=int:\n",
    "        r = int(255*r)\n",
    "        g = int(255*g)\n",
    "        b = int(255*b)\n",
    "    return \"#{:02x}{:02x}{:02x}\".format(r,g,b)\n",
    "\n",
    "def mystyle(x):\n",
    "    fo = 0.0\n",
    "    color = 'white'\n",
    "    if 'color' in x['properties'].keys():\n",
    "        fo= np.tanh(10*x['properties']['transp'])\n",
    "        color=x['properties']['color']\n",
    "    return {'weight': 1.5, 'fillOpacity': fo,'color': color}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = pd.read_csv('./data/processed_trajectories.csv')\n",
    "zn_pos = pd.read_csv('./data/zones_centroids.csv')\n",
    "\n",
    "zone_coords = zn_pos.set_index('zone')[['latitude', 'longitude']].to_dict(orient='index')\n",
    "\n",
    "# Función para obtener latitud y longitud de una zona\n",
    "def get_lat_long(zone):\n",
    "    if zone in zone_coords:\n",
    "        return zone_coords[zone]['latitude'], zone_coords[zone]['longitude']\n",
    "    else:\n",
    "        return None, None\n",
    "\n",
    "# Crear las identificaciones únicas de las torres\n",
    "towers_id = np.arange(1, 135, 1)  # Asegúrate de que esto coincida con las zonas válidas en tu conjunto de datos\n",
    "n_towers = len(towers_id)\n",
    "codes_onehot = np.eye(n_towers)  # Generar codificación one-hot para las torres\n",
    "\n",
    "# Crear una lista de coordenadas para todas las zonas\n",
    "ll = {zone: get_lat_long(zone) for zone in towers_id}\n",
    "ll[None] = (None, None)  # Añadir coordenadas nulas para zonas no válidas\n",
    "\n",
    "def input_labels(data):\n",
    "    \"\"\"\n",
    "    Generar entradas (`inputs`) y etiquetas (`predict`) a partir de los datos procesados.\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "    predict = []\n",
    "\n",
    "    for _, row in data.iterrows():\n",
    "        zone_start, zone_middle, zone_end, f_time = row['zone_start'], row['zone_middle'], row['zone_end'], row['f_time']\n",
    "        \n",
    "        # Obtener coordenadas\n",
    "        lat_start, long_start = ll.get(zone_start, (None, None))\n",
    "        lat_end, long_end = ll.get(zone_end, (None, None))\n",
    "        \n",
    "        # Verificar si las coordenadas son válidas\n",
    "        if None in (lat_start, long_start, lat_end, long_end):\n",
    "            continue  # Ignorar trayectorias con zonas inválidas\n",
    "        \n",
    "        zone_middle = int(zone_middle)  # Convertir a entero\n",
    "        \n",
    "        # Validar que el índice sea válido dentro de codes_onehot\n",
    "        if 1 <= zone_middle <= len(codes_onehot):\n",
    "            # Crear entrada\n",
    "            inputs.append([long_start, lat_start, long_end, lat_end, f_time])\n",
    "            \n",
    "            # Crear etiqueta one-hot para la zona intermedia\n",
    "            predict.append(codes_onehot[zone_middle - 1])\n",
    "    \n",
    "    return np.array(inputs), np.array(predict)\n",
    "\n",
    "# Generar datos de entrada y etiquetas\n",
    "inputs_v2, predict = input_labels(trajectories)\n",
    "\n",
    "# Barajar los datos para aleatoriedad\n",
    "indices = np.arange(len(inputs_v2))\n",
    "np.random.shuffle(indices)\n",
    "inputs_v2 = inputs_v2[indices]\n",
    "predict = predict[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fd = open('./data/transport_zones.json', 'r')\n",
    "transp_zones_json = json.load(fd)\n",
    "fd.close()\n",
    "\n",
    "fd = open('./data/voronoi_properties.json', 'r')\n",
    "voronois_json = json.load(fd)\n",
    "fd.close()\n",
    "\n",
    "voronois_habana_features = filter(lambda f : f['properties']['province'] == 'La Habana' , voronois_json['features'])\n",
    "voronois_habana_features = [f for f in voronois_habana_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 2\n",
    "end = 33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(inputs_v2[:,0:4])\n",
    "\n",
    "# Asumimos que `model` es una instancia de TrajectoryModel\n",
    "# y está cargado con los pesos entrenados.\n",
    "model.eval()  # Configura el modelo en modo de evaluación\n",
    "\n",
    "# Normalización\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "scaler.fit(inputs_v2[:, 0:4])\n",
    "\n",
    "# Definir las zonas A y B\n",
    "ZonaA = (zn_pos['longitude'][start - 1], zn_pos['latitude'][start - 1])\n",
    "ZonaB = (zn_pos['longitude'][end - 1], zn_pos['latitude'][end - 1])\n",
    "\n",
    "# Preparar valores de entrada\n",
    "input_val = np.zeros((100, 5))\n",
    "X = scaler.transform(np.array([ZonaA[0], ZonaA[1], ZonaB[0], ZonaB[1]]).reshape(1, -1))[0]\n",
    "for i in range(4):\n",
    "    input_val[:, i] = X[i]\n",
    "input_val[:, 4] = np.arange(0, 1, 0.01)\n",
    "\n",
    "pb = np.zeros((input_val.shape[0], n_towers))  # Matriz de resultados\n",
    "\n",
    "with torch.no_grad():  # Deshabilitar cálculo de gradientes\n",
    "    for i in range(input_val.shape[0]):\n",
    "        tensor_input = torch.tensor(input_val[i].reshape(1, 5), dtype=torch.float32).to(device)  # Convertir a tensor y mover al dispositivo\n",
    "        output = model(tensor_input).cpu().numpy()  # Obtener salida y mover a CPU para usar con NumPy\n",
    "        pb[i] = output\n",
    "\n",
    "# Procesamiento de zonas y colores\n",
    "[intervals, zonenumber] = pb.shape\n",
    "zonesincolor = np.zeros((zonenumber, 3))\n",
    "tonorm = np.zeros(zonenumber)\n",
    "norm_fac = np.zeros(zonenumber)\n",
    "\n",
    "for i in range(intervals):\n",
    "    zones = pb[i, :].copy()\n",
    "    Max = max(zones)\n",
    "    col = cm.get_cmap('viridis')(i * 1.0 / intervals)\n",
    "    zones_sorted = np.sort(zones)[::-1]\n",
    "    for ki in range(10):\n",
    "        index_ = np.where(pb[i, :] == zones_sorted[ki])[0][0]\n",
    "        tonorm[index_] += 1 / (ki + 1)\n",
    "    for j in range(zonenumber):\n",
    "        frac = (pb[i, j]) / Max\n",
    "        norm_fac[j] += frac\n",
    "        col1 = frac * np.array(col)\n",
    "        zonesincolor[j, 0] += col1[0]\n",
    "        zonesincolor[j, 1] += col1[1]\n",
    "        zonesincolor[j, 2] += col1[2]\n",
    "\n",
    "for i in range(3):\n",
    "    zonesincolor[:, i] = np.array([zonesincolor[j, i] / (1e-5 + norm_fac[j]) for j in range(zonenumber)])\n",
    "\n",
    "tonorm = tonorm / max(tonorm)\n",
    "\n",
    "# Actualizar g2 con colores y transparencia\n",
    "g2 = transp_zones_json.copy()\n",
    "for f in g2['features']:\n",
    "    j = int(f['properties']['NO_DE_ZONA']) - 1\n",
    "    f['properties']['color'] = rgb2hex(zonesincolor[j, 0], zonesincolor[j, 1], zonesincolor[j, 2])\n",
    "    f['properties']['transp'] = tonorm[j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location=[23.0826, -82.2845], zoom_start=11, tiles='openstreetmap')\n",
    "\n",
    "zones_geojson = folium.GeoJson(g2, \n",
    "                               style_function = lambda x:mystyle(x), \n",
    "                               tooltip=folium.features.GeoJsonTooltip(fields = ['NO_DE_ZONA']))\n",
    "\n",
    "folium.Marker(location=ll[start], icon=folium.Icon(color='red', icon='circle', prefix='fa')).add_to(map)\n",
    "folium.Marker(location=ll[end], icon=folium.Icon(color='red', icon='circle', prefix='fa')).add_to(map)\n",
    "\n",
    "zones_geojson.add_to(map)\n",
    "\n",
    "map"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
